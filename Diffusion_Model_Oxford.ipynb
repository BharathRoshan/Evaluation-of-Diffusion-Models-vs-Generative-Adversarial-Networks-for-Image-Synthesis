{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BharathRoshan/Evaluation-of-Diffusion-Models-vs-Generative-Adversarial-Networks-for-Image-Synthesis/blob/main/Diffusion_Model_Oxford.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "j7GQg2SgPXi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "5OTuIABWPgzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prdc\n",
        "!pip install tensorboardX\n",
        "!pip install fire\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "from torch.nn import init\n",
        "\n",
        "\n",
        "import warnings\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3\n",
        "from prdc import compute_prdc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from scipy.stats import entropy\n",
        "\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import warnings\n",
        "from absl import app, flags\n",
        "\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "from torchvision.datasets import Flowers102\n",
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms\n",
        "from tqdm import trange\n",
        "\n",
        "import fire\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "d_-oNSzkPihT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUeKzbX1fhdq"
      },
      "outputs": [],
      "source": [
        "def extract(v, t, x_shape):\n",
        "    \n",
        "    out = torch.gather(v, index=t, dim=0).float()\n",
        "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
        "\n",
        "\n",
        "class GaussianDiffusionTrainer(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "\n",
        "        self.register_buffer(\n",
        "            'betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer(\n",
        "            'sqrt_alphas_bar', torch.sqrt(alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))\n",
        "\n",
        "    def forward(self, x_0):\n",
        "        \"\"\"\n",
        "        Algorithm 1.\n",
        "        \"\"\"\n",
        "        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)\n",
        "        noise = torch.randn_like(x_0)\n",
        "        x_t = (\n",
        "            extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 +\n",
        "            extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise)\n",
        "        loss = F.mse_loss(self.model(x_t, t), noise, reduction='none')\n",
        "        return loss\n",
        "\n",
        "\n",
        "class GaussianDiffusionSampler(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T, img_size=32,\n",
        "                 mean_type='eps', var_type='fixedlarge'):\n",
        "        assert mean_type in ['xprev' 'xstart', 'epsilon']\n",
        "        assert var_type in ['fixedlarge', 'fixedsmall']\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "        self.img_size = img_size\n",
        "        self.mean_type = mean_type\n",
        "        self.var_type = var_type\n",
        "\n",
        "        self.register_buffer(\n",
        "            'betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer(\n",
        "            'sqrt_recip_alphas_bar', torch.sqrt(1. / alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'sqrt_recipm1_alphas_bar', torch.sqrt(1. / alphas_bar - 1))\n",
        "\n",
        "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        self.register_buffer(\n",
        "            'posterior_var',\n",
        "            self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))\n",
        "        # below: log calculation clipped because the posterior variance is 0 at\n",
        "        # the beginning of the diffusion chain\n",
        "        self.register_buffer(\n",
        "            'posterior_log_var_clipped',\n",
        "            torch.log(\n",
        "                torch.cat([self.posterior_var[1:2], self.posterior_var[1:]])))\n",
        "        self.register_buffer(\n",
        "            'posterior_mean_coef1',\n",
        "            torch.sqrt(alphas_bar_prev) * self.betas / (1. - alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'posterior_mean_coef2',\n",
        "            torch.sqrt(alphas) * (1. - alphas_bar_prev) / (1. - alphas_bar))\n",
        "\n",
        "    def q_mean_variance(self, x_0, x_t, t):\n",
        "        \"\"\"\n",
        "        Compute the mean and variance of the diffusion posterior\n",
        "        q(x_{t-1} | x_t, x_0)\n",
        "        \"\"\"\n",
        "        assert x_0.shape == x_t.shape\n",
        "        posterior_mean = (\n",
        "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_0 +\n",
        "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
        "        )\n",
        "        posterior_log_var_clipped = extract(\n",
        "            self.posterior_log_var_clipped, t, x_t.shape)\n",
        "        return posterior_mean, posterior_log_var_clipped\n",
        "\n",
        "    def predict_xstart_from_eps(self, x_t, t, eps):\n",
        "        assert x_t.shape == eps.shape\n",
        "        return (\n",
        "            extract(self.sqrt_recip_alphas_bar, t, x_t.shape) * x_t -\n",
        "            extract(self.sqrt_recipm1_alphas_bar, t, x_t.shape) * eps\n",
        "        )\n",
        "\n",
        "    def predict_xstart_from_xprev(self, x_t, t, xprev):\n",
        "        assert x_t.shape == xprev.shape\n",
        "        return (  # (xprev - coef2*x_t) / coef1\n",
        "            extract(\n",
        "                1. / self.posterior_mean_coef1, t, x_t.shape) * xprev -\n",
        "            extract(\n",
        "                self.posterior_mean_coef2 / self.posterior_mean_coef1, t,\n",
        "                x_t.shape) * x_t\n",
        "        )\n",
        "\n",
        "    def p_mean_variance(self, x_t, t):\n",
        "        # below: only log_variance is used in the KL computations\n",
        "        model_log_var = {\n",
        "            # for fixedlarge, we set the initial (log-)variance like so to\n",
        "            # get a better decoder log likelihood\n",
        "            'fixedlarge': torch.log(torch.cat([self.posterior_var[1:2],\n",
        "                                               self.betas[1:]])),\n",
        "            'fixedsmall': self.posterior_log_var_clipped,\n",
        "        }[self.var_type]\n",
        "        model_log_var = extract(model_log_var, t, x_t.shape)\n",
        "\n",
        "        # Mean parameterization\n",
        "        if self.mean_type == 'xprev':       # the model predicts x_{t-1}\n",
        "            x_prev = self.model(x_t, t)\n",
        "            x_0 = self.predict_xstart_from_xprev(x_t, t, xprev=x_prev)\n",
        "            model_mean = x_prev\n",
        "        elif self.mean_type == 'xstart':    # the model predicts x_0\n",
        "            x_0 = self.model(x_t, t)\n",
        "            model_mean, _ = self.q_mean_variance(x_0, x_t, t)\n",
        "        elif self.mean_type == 'epsilon':   # the model predicts epsilon\n",
        "            eps = self.model(x_t, t)\n",
        "            x_0 = self.predict_xstart_from_eps(x_t, t, eps=eps)\n",
        "            model_mean, _ = self.q_mean_variance(x_0, x_t, t)\n",
        "        else:\n",
        "            raise NotImplementedError(self.mean_type)\n",
        "        x_0 = torch.clip(x_0, -1., 1.)\n",
        "\n",
        "        return model_mean, model_log_var\n",
        "\n",
        "    def forward(self, x_T):\n",
        "        \"\"\"\n",
        "        Algorithm 2.\n",
        "        \"\"\"\n",
        "        x_t = x_T\n",
        "        for time_step in reversed(range(self.T)):\n",
        "            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step\n",
        "            mean, log_var = self.p_mean_variance(x_t=x_t, t=t)\n",
        "            # no noise when t == 0\n",
        "            if time_step > 0:\n",
        "                noise = torch.randn_like(x_t)\n",
        "            else:\n",
        "                noise = 0\n",
        "            x_t = mean + torch.exp(0.5 * log_var) * noise\n",
        "        x_0 = x_t\n",
        "        return torch.clip(x_0, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, T, d_model, dim):\n",
        "        assert d_model % 2 == 0\n",
        "        super().__init__()\n",
        "        emb = torch.arange(0, d_model, step=2) / d_model * math.log(10000)\n",
        "        emb = torch.exp(-emb)\n",
        "        pos = torch.arange(T).float()\n",
        "        emb = pos[:, None] * emb[None, :]\n",
        "        assert list(emb.shape) == [T, d_model // 2]\n",
        "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        assert list(emb.shape) == [T, d_model // 2, 2]\n",
        "        emb = emb.view(T, d_model)\n",
        "\n",
        "        self.timembedding = nn.Sequential(\n",
        "            nn.Embedding.from_pretrained(emb),\n",
        "            nn.Linear(d_model, dim),\n",
        "            Swish(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                init.xavier_uniform_(module.weight)\n",
        "                init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, t):\n",
        "        emb = self.timembedding(t)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.main.weight)\n",
        "        init.zeros_(self.main.bias)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.main.weight)\n",
        "        init.zeros_(self.main.bias)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        _, _, H, W = x.shape\n",
        "        x = F.interpolate(\n",
        "            x, scale_factor=2, mode='nearest')\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
        "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
        "            init.xavier_uniform_(module.weight)\n",
        "            init.zeros_(module.bias)\n",
        "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.group_norm(x)\n",
        "        q = self.proj_q(h)\n",
        "        k = self.proj_k(h)\n",
        "        v = self.proj_v(h)\n",
        "\n",
        "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        k = k.view(B, C, H * W)\n",
        "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
        "        assert list(w.shape) == [B, H * W, H * W]\n",
        "        w = F.softmax(w, dim=-1)\n",
        "\n",
        "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        h = torch.bmm(w, v)\n",
        "        assert list(h.shape) == [B, H * W, C]\n",
        "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "        h = self.proj(h)\n",
        "\n",
        "        return x + h\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
        "        super().__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(32, in_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        self.temb_proj = nn.Sequential(\n",
        "            Swish(),\n",
        "            nn.Linear(tdim, out_ch),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(32, out_ch),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        if in_ch != out_ch:\n",
        "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        if attn:\n",
        "            self.attn = AttnBlock(out_ch)\n",
        "        else:\n",
        "            self.attn = nn.Identity()\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                init.xavier_uniform_(module.weight)\n",
        "                init.zeros_(module.bias)\n",
        "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
        "        \n",
        "    def forward(self, x, temb):\n",
        "        h = self.block1(x)\n",
        "        h += self.temb_proj(temb)[:, :, None, None]\n",
        "        h = self.block2(h)\n",
        "\n",
        "        h = h + self.shortcut(x)\n",
        "        h = self.attn(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
        "        super().__init__()\n",
        "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
        "        tdim = ch * 4\n",
        "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
        "\n",
        "        self.head = nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.downblocks = nn.ModuleList()\n",
        "        chs = [ch]  # record output channel when dowmsample for upsample\n",
        "        now_ch = ch\n",
        "        for i, mult in enumerate(ch_mult):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks):\n",
        "                self.downblocks.append(ResBlock(\n",
        "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
        "                    dropout=dropout, attn=(i in attn)))\n",
        "                now_ch = out_ch\n",
        "                chs.append(now_ch)\n",
        "            if i != len(ch_mult) - 1:\n",
        "                self.downblocks.append(DownSample(now_ch))\n",
        "                chs.append(now_ch)\n",
        "\n",
        "        self.middleblocks = nn.ModuleList([\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
        "        ])\n",
        "\n",
        "        self.upblocks = nn.ModuleList()\n",
        "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks + 1):\n",
        "                self.upblocks.append(ResBlock(\n",
        "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
        "                    dropout=dropout, attn=(i in attn)))\n",
        "                now_ch = out_ch\n",
        "            if i != 0:\n",
        "                self.upblocks.append(UpSample(now_ch))\n",
        "        assert len(chs) == 0\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            nn.GroupNorm(32, now_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(now_ch, 3, 3, stride=1, padding=1)\n",
        "        )\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.head.weight)\n",
        "        init.zeros_(self.head.bias)\n",
        "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
        "        init.zeros_(self.tail[-1].bias)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        # Timestep embedding\n",
        "        temb = self.time_embedding(t)\n",
        "        # Downsampling\n",
        "        h = self.head(x)\n",
        "        hs = [h]\n",
        "        for layer in self.downblocks:\n",
        "            h = layer(h, temb)\n",
        "            hs.append(h)\n",
        "        # Middle\n",
        "        for layer in self.middleblocks:\n",
        "            h = layer(h, temb)\n",
        "        # Upsampling\n",
        "        for layer in self.upblocks:\n",
        "            if isinstance(layer, ResBlock):\n",
        "                h = torch.cat([h, hs.pop()], dim=1)\n",
        "            h = layer(h, temb)\n",
        "        h = self.tail(h)\n",
        "\n",
        "        assert len(hs) == 0\n",
        "        return h\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    batch_size = 8\n",
        "    model = UNet(\n",
        "        T=1000, ch=128, ch_mult=[1, 2, 2, 2], attn=[1],\n",
        "        num_res_blocks=2, dropout=0.1)\n",
        "    x = torch.randn(batch_size, 3, 32, 32)\n",
        "    t = torch.randint(1000, (batch_size, ))\n",
        "    y = model(x, t)"
      ],
      "metadata": {
        "id": "BlQdW2WFfllR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationMetric:\n",
        "    def __init__(self, transform_input=True):\n",
        "        self.transform_input = transform_input\n",
        "        self.ngpu = 0\n",
        "        self.device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and self.ngpu>0) else \"cpu\")\n",
        "        self.InceptionV3 = inception_v3(pretrained=True, transform_input=False)\n",
        "        self.InceptionV3.eval()\n",
        "\n",
        "    def evaluate(self, real_img, generated_img):\n",
        "        mu1, sigma1, mu2, sigma2, pre_recall = self.calc_activation_stats(real_img, generated_img)\n",
        "        fid = self.compute_fid(mu1, sigma1, mu2, sigma2)\n",
        "\n",
        "        print('FID:', fid)\n",
        "        print('Precision:', pre_recall['precision'])\n",
        "        print('Recall:', pre_recall['recall'])\n",
        "\n",
        "    def build_maps(self, x):\n",
        "        if list(x.shape[-2:]) != [299, 299]:\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                x = F.interpolate(x, size=[299, 299], mode='bilinear')\n",
        "        if self.transform_input:\n",
        "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "        with torch.no_grad():\n",
        "            x = self.InceptionV3.Conv2d_1a_3x3(x)\n",
        "            x = self.InceptionV3.Conv2d_2a_3x3(x)\n",
        "            x = self.InceptionV3.Conv2d_2b_3x3(x)\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            x = self.InceptionV3.Conv2d_3b_1x1(x)\n",
        "            x = self.InceptionV3.Conv2d_4a_3x3(x)\n",
        "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "            x = self.InceptionV3.Mixed_5b(x)\n",
        "            x = self.InceptionV3.Mixed_5c(x)\n",
        "            x = self.InceptionV3.Mixed_5d(x)\n",
        "            x = self.InceptionV3.Mixed_6a(x)\n",
        "            x = self.InceptionV3.Mixed_6b(x)\n",
        "            x = self.InceptionV3.Mixed_6c(x)\n",
        "            x = self.InceptionV3.Mixed_6d(x)\n",
        "            x = self.InceptionV3.Mixed_6e(x)\n",
        "            x = self.InceptionV3.Mixed_7a(x)\n",
        "            x = self.InceptionV3.Mixed_7b(x)\n",
        "            x = self.InceptionV3.Mixed_7c(x)\n",
        "            x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "            return x\n",
        "\n",
        "    def compute_fid(self, mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "        mu1 = np.atleast_1d(mu1)\n",
        "        mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "        sigma1 = np.atleast_2d(sigma1)\n",
        "        sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "        assert mu1.shape == mu2.shape, \\\n",
        "            'Training and test mean vectors have different lengths'\n",
        "        assert sigma1.shape == sigma2.shape, \\\n",
        "            'Training and test covariances have different dimensions'\n",
        "\n",
        "        diff = mu1 - mu2\n",
        "\n",
        "        covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "        if not np.isfinite(covmean).all():\n",
        "            msg = ('fid calculation produces singular product; '\n",
        "                   'adding %s to diagonal of cov estimates') % eps\n",
        "            print(msg)\n",
        "            offset = np.eye(sigma1.shape[0]) * eps\n",
        "            covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "        if np.iscomplexobj(covmean):\n",
        "            if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "                m = np.max(np.abs(covmean.imag))\n",
        "                raise ValueError('Imaginary component {}'.format(m))\n",
        "            covmean = covmean.real\n",
        "\n",
        "        tr_covmean = np.trace(covmean)\n",
        "\n",
        "        return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
        "\n",
        "    def calc_activation_stats(self, real_img, generated_img, batch_size=64):\n",
        "        assert real_img.shape[0] == generated_img.shape[0]\n",
        "        real_images = real_img[np.random.permutation(real_img.shape[0])]\n",
        "\n",
        "        generated_images = generated_img[np.random.permutation(generated_img.shape[0])]\n",
        "        nearest_k = 3\n",
        "        real_maps = []\n",
        "        generated_maps = []\n",
        "        for s in range(int(math.ceil(real_images.shape[0] / batch_size))):\n",
        "            sidx = np.arange(batch_size * s, min(batch_size * (s + 1), real_images.shape[0]))\n",
        "            real_maps.append(self.build_maps(real_images[sidx].to(device=self.device)).detach().to(device='cpu'))\n",
        "            generated_maps.append(\n",
        "                self.build_maps(generated_images[sidx].to(device=self.device)).detach().to(device='cpu'))\n",
        "\n",
        "        real_maps = np.squeeze(torch.cat(real_maps).numpy())\n",
        "        generated_maps = np.squeeze(torch.cat(generated_maps).numpy())\n",
        "\n",
        "        mu1 = np.mean(generated_maps, axis=0)\n",
        "        mu2 = np.mean(real_maps, axis=0)\n",
        "        sigma1 = np.cov(generated_maps, rowvar=False)\n",
        "        sigma2 = np.cov(real_maps, rowvar=False)\n",
        "        prec_recall = compute_prdc(real_maps, generated_maps, nearest_k)\n",
        "\n",
        "        return mu1, sigma1, mu2, sigma2, prec_recall"
      ],
      "metadata": {
        "id": "R4gCdRjRne5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "from torch.utils.data import DataLoader\n",
        "def flowerdata(batch_size):\n",
        "  transform=transforms.Compose([\n",
        "            transforms.Resize((32,32)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "  dataset = Flowers102('data/flower_data', transform=transform, split='train', download=True)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "seCwt3PNSZKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infiniteloop(dataloader):\n",
        "    while True:\n",
        "        for x, y in iter(dataloader):\n",
        "            yield x"
      ],
      "metadata": {
        "id": "ykjv8i-1TANM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_workers = 3\n",
        "channels = 64\n",
        "channels_mult = [1, 2, 2, 2]\n",
        "attention = [1]\n",
        "num_res_blocks = 2\n",
        "beta_1 = 1e-4\n",
        "beta_T = 0.02\n",
        "T = 4000\n",
        "learning_rate = 0.001\n",
        "total_steps = 100000\n",
        "grad_clip = 1.\n",
        "img_size = 32\n",
        "warmup = 5000\n",
        "batch_size = 64\n",
        "num_workers = 4\n",
        "ema_decay = 0.9999\n",
        "sample_size = 64\n",
        "eval_step = 0\n",
        "ngpu = 0\n",
        "mean_type = 'epsilon'\n",
        "var_type = 'fixedlarge'\n",
        "num_images = 50000\n",
        "dropout = 0.1\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "#writer = SummaryWriter('/content/drive/MyDrive/DiffusionModel/logs')\n",
        "dataloader = flowerdata(batch_size)\n",
        "\n",
        "datalooper = infiniteloop(dataloader)\n",
        "\n",
        "\n",
        "def ema(source, target, decay):\n",
        "    source_dict = source.state_dict()\n",
        "    target_dict = target.state_dict()\n",
        "    for key in source_dict.keys():\n",
        "        target_dict[key].data.copy_(\n",
        "            target_dict[key].data * decay +\n",
        "            source_dict[key].data * (1 - decay))\n",
        "\n",
        "\n",
        "def warmup_lr(step):\n",
        "    return min(step, warmup) / warmup\n",
        "\n",
        "\n",
        "def train(checkpoint='/content/drive/MyDrive/DiffusionModel_Oxford_Checkpoints/Iter460000.pth'):\n",
        "\n",
        "    if not os.path.exists('/content/drive/MyDrive/DiffusionModel_Oxford_Gen'):\n",
        "            os.mkdir('/content/drive/MyDrive/DiffusionModel_Oxford_Gen')\n",
        "\n",
        "    if not os.path.exists('/content/drive/MyDrive/DiffusionModel_Oxford_Checkpoints'):\n",
        "            os.mkdir('/content/drive/MyDrive/DiffusionModel_Oxford_Checkpoints')\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    # model setup\n",
        "    net_model = UNet(\n",
        "        T=T, ch=channels, ch_mult=channels_mult, attn=attention,\n",
        "        num_res_blocks=num_res_blocks, dropout=dropout)\n",
        "    ema_model = copy.deepcopy(net_model)\n",
        "    optim = torch.optim.AdamW(net_model.parameters(), lr=learning_rate)\n",
        "    sched = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=warmup_lr)\n",
        "    trainer = GaussianDiffusionTrainer(\n",
        "        net_model, beta_1, beta_T, T).to(device)\n",
        "    net_sampler = GaussianDiffusionSampler(\n",
        "        net_model, beta_1, beta_T, T, img_size,\n",
        "        mean_type, var_type).to(device)\n",
        "    ema_sampler = GaussianDiffusionSampler(\n",
        "        ema_model, beta_1, beta_T, T, img_size,\n",
        "        mean_type, var_type).to(device)\n",
        "\n",
        "    x_T = torch.randn(sample_size, 3, img_size, img_size)\n",
        "    x_T = x_T.to(device)\n",
        "\n",
        "    \n",
        "    \n",
        "    # start training\n",
        "    with trange(total_steps, dynamic_ncols=True) as pbar:\n",
        "        for step in pbar:\n",
        "\n",
        "            # train\n",
        "            if checkpoint:\n",
        "              chkpoint = torch.load(checkpoint)\n",
        "              net_model.load_state_dict(chkpoint['net_model'])\n",
        "              ema_model.load_state_dict(chkpoint['ema_model'])\n",
        "              sched.load_state_dict(chkpoint['sched'])\n",
        "              optim.load_state_dict(chkpoint['optim'])\n",
        "            optim.zero_grad()\n",
        "            x_0 = next(datalooper).to(device)\n",
        "            #print(x_0.shape)\n",
        "            loss = trainer(x_0).mean()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                net_model.parameters(), grad_clip)\n",
        "            optim.step()\n",
        "            sched.step()\n",
        "            ema(net_model, ema_model, ema_decay)\n",
        "\n",
        "            # log\n",
        "            #writer.add_scalar('loss', scalar_value = loss.item(), global_step=step)\n",
        "            pbar.set_postfix(loss='%.3f' % loss.item())\n",
        "\n",
        "            # sample\n",
        "            if step % 10000 == 0:\n",
        "                net_model.eval()\n",
        "                with torch.no_grad():\n",
        "                    gen = ema_sampler(x_T)\n",
        "                    #grid = (make_grid(x_0) + 1) / 2\n",
        "                    #print(gen.shape)\n",
        "                    save_image(gen, '/content/drive/MyDrive/DiffusionModel_Oxford_Gen/Iter4{}.png'.format(step))\n",
        "                net_model.train()\n",
        "                eval = EvaluationMetric()\n",
        "                eval.evaluate(x_0, gen)\n",
        "            #writer.close()\n",
        "\n",
        "\n",
        "            # save\n",
        "            if step%10000 == 0:\n",
        "                torch.save({\n",
        "                    'net_model': net_model.state_dict(),\n",
        "                    'ema_model': ema_model.state_dict(),\n",
        "                    'sched': sched.state_dict(),\n",
        "                    'optim': optim.state_dict(),\n",
        "                    'step': step,\n",
        "                    'x_T': x_T,\n",
        "                }, '/content/drive/MyDrive/DiffusionModel_Oxford_Checkpoints/Iter4{}.pth'.format(step))"
      ],
      "metadata": {
        "id": "8qx5I2zDfr_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "-CXwSjZfed3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/DiffusionModel/logs"
      ],
      "metadata": {
        "id": "Ic89r2nHVSEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "1dqF_1gnjjnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCvJlMT0kInB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}